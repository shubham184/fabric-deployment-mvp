{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bronze Layer Data Ingestion\n",
        "This notebook handles raw data ingestion for Contoso Corp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import current_timestamp, input_file_name, lit\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Contoso Bronze Ingestion\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "BRONZE_LAKEHOUSE = \"ctso-bronze-lakehouse\"\n",
        "SOURCE_PATH = \"abfss://raw@contosostorage.dfs.core.windows.net/\"\n",
        "BRONZE_PATH = f\"Tables/{BRONZE_LAKEHOUSE}/\"\n",
        "\n",
        "# Data sources to ingest\n",
        "data_sources = [\n",
        "    {\"name\": \"customers\", \"format\": \"csv\", \"path\": \"customers/\"},\n",
        "    {\"name\": \"orders\", \"format\": \"parquet\", \"path\": \"orders/\"},\n",
        "    {\"name\": \"products\", \"format\": \"json\", \"path\": \"products/\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ingestion function\n",
        "def ingest_to_bronze(source_info):\n",
        "    \"\"\"Ingest raw data to bronze layer with metadata.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Starting ingestion for {source_info['name']}\")\n",
        "        \n",
        "        # Read source data\n",
        "        df = spark.read \\\n",
        "            .format(source_info['format']) \\\n",
        "            .option(\"header\", \"true\") \\\n",
        "            .option(\"inferSchema\", \"true\") \\\n",
        "            .load(SOURCE_PATH + source_info['path'])\n",
        "        \n",
        "        # Add metadata columns\n",
        "        df = df.withColumn(\"_ingestion_timestamp\", current_timestamp()) \\\n",
        "               .withColumn(\"_source_file\", input_file_name()) \\\n",
        "               .withColumn(\"_record_source\", lit(source_info['name']))\n",
        "        \n",
        "        # Write to bronze layer\n",
        "        output_path = BRONZE_PATH + source_info['name']\n",
        "        df.write \\\n",
        "          .mode(\"append\") \\\n",
        "          .format(\"delta\") \\\n",
        "          .save(output_path)\n",
        "        \n",
        "        logger.info(f\"✓ Successfully ingested {df.count()} records for {source_info['name']}\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"✗ Failed to ingest {source_info['name']}: {str(e)}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run ingestion for all data sources\n",
        "results = []\n",
        "for source in data_sources:\n",
        "    success = ingest_to_bronze(source)\n",
        "    results.append({\"source\": source['name'], \"success\": success})\n",
        "\n",
        "# Summary\n",
        "successful = sum(1 for r in results if r['success'])\n",
        "print(f\"\\nIngestion Complete: {successful}/{len(data_sources)} sources processed successfully\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
